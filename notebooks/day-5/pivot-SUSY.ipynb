{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H7JGD6RlLYVz"
   },
   "source": [
    "# Learning to pivot\n",
    "\n",
    "Main paper: https://arxiv.org/abs/1611.01046\n",
    "\n",
    "In the notebook, we are going to make classifier's predictions independent from a *nuisance* parameters.\n",
    "While nuisance parameters themselves can be not explicitely present in the dataset, they can be partially inffered from the rest of the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import mlhep2019\n",
    "except ModuleNotFoundError:\n",
    "    import subprocess as sp\n",
    "    result = sp.run(\n",
    "        ['pip', 'install', 'git+https://github.com/yandexdataschool/mlhep2019.git'],\n",
    "        stdout=sp.PIPE, stderr=sp.PIPE\n",
    "    )\n",
    "    \n",
    "    if result.returncode != 0:\n",
    "        print(result.stdout.decode('utf-8'))\n",
    "        print(result.stderr.decode('utf-8'))\n",
    "    \n",
    "    import mlhep2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q56Jl-vVBqqy"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data\n",
    "\n",
    "from mlhep2019.pivot import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "OF5sS9uREo_x",
    "outputId": "af277d3a-2f9d-498d-f58d-3458e4b07f93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeForce GTX 1080\n"
     ]
    }
   ],
   "source": [
    "for i in range(torch.cuda.device_count()):\n",
    "  print(torch.cuda.get_device_name(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uQ24YaviBqrB"
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "  device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "  device = \"cpu\"\n",
    "  print('Using CPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OTVi7FB0BqrF"
   },
   "source": [
    "## Downloading SUSY dataset\n",
    "\n",
    "The dataset can be found at https://archive.ics.uci.edu/ml/datasets/SUSY\n",
    "\n",
    "The original paper is:\n",
    "Baldi, P., P. Sadowski, and D. Whiteson. “Searching for Exotic Particles in High-energy Physics with Deep Learning.” Nature Communications 5 (July 2, 2014)\n",
    "\n",
    "### Data Set Information:\n",
    "\n",
    "Provide all relevant informatioThe data has been produced using Monte Carlo simulations. The first 8 features are kinematic properties measured by the particle detectors in the accelerator. The last ten features are functions of the first 8 features; these are high-level features derived by physicists to help discriminate between the two classes. There is an interest in using deep learning methods to obviate the need for physicists to manually develop such features. Benchmark results using Bayesian Decision Trees from a standard physics package and 5-layer neural networks and the dropout algorithm are presented in the original paper. The last 500,000 examples are used as a test set.n about your data set.\n",
    "\n",
    "### Attribute Information:\n",
    "\n",
    "The first column is the class label (1 for signal, 0 for background), followed by the 18 features (8 low-level features then 10 high-level features):: lepton 1 pT, lepton 1 eta, lepton 1 phi, lepton 2 pT, lepton 2 eta, lepton 2 phi, missing energy magnitude, missing energy phi, MET_rel, axial MET, M_R, M_TR_2, R, MT2, S_R, M_Delta_R, dPhi_r_b, cos(theta_r1). For detailed information about each feature see the original paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DSH6_vG1BqrH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000000\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    f = np.load('SUSY/susy.npz')\n",
    "    data, labels = f['data'], f['labels']\n",
    "except FileNotFoundError:\n",
    "    data, labels = get_susy('SUSY/')\n",
    "    np.savez('SUSY/susy.npz', data=data, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, labels_train, data_test, labels_test = split(data, labels, split_ratios=(10, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mean, data_std = np.mean(data_train, axis=0), np.std(data_train, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train -= data_mean[None, :]\n",
    "data_train /= data_std[None, :]\n",
    "\n",
    "### never use test statistics to transform the test dataset!\n",
    "data_test -= data_mean[None, :]\n",
    "data_test /= data_std[None, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, nuisance_train = data_train[:, 1:], data_train[:, 0]\n",
    "data_test, nuisance_test = data_test[:, 1:], data_test[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = plt.hist(\n",
    "    [nuisance_train[labels_train > 0.5], nuisance_train[labels_train < 0.5]],\n",
    "    bins=100, histtype='step'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, z_train, z_test = [\n",
    "    torch.tensor(x).to(device)\n",
    "    for x in [data_train, data_test, labels_train, labels_test, nuisance_train, nuisance_test]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = torch.utils.data.TensorDataset(X_test, y_test, z_test)\n",
    "loader_test =  torch.utils.data.DataLoader(dataset_test, batch_size=1024, shuffle=False)\n",
    "\n",
    "def get_test_predictions(model):\n",
    "    with torch.no_grad():\n",
    "        return np.concatenate([\n",
    "            torch.sigmoid(model(X_batch)).to('cpu').detach().numpy()\n",
    "            for X_batch, _, _ in loader_test\n",
    "        ], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(torch.nn.Module):\n",
    "    ### define classifier here\n",
    "    ### don't forget about torch.squeeze\n",
    "    def __init__(self, ):\n",
    "        super(Classifier, self).__init__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Classifier().to(device)\n",
    "\n",
    "### define loss here\n",
    "loss_fn_clf = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "optimizer got an empty parameter list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-58506496e7e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epoches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mopt_clf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epoches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.7/envs/py3/lib/python3.6/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, lr, betas, eps, weight_decay, amsgrad)\u001b[0m\n\u001b[1;32m     40\u001b[0m         defaults = dict(lr=lr, betas=betas, eps=eps,\n\u001b[1;32m     41\u001b[0m                         weight_decay=weight_decay, amsgrad=amsgrad)\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.7/envs/py3/lib/python3.6/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, defaults)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mparam_groups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"optimizer got an empty parameter list\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0mparam_groups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mparam_groups\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: optimizer got an empty parameter list"
     ]
    }
   ],
   "source": [
    "n_epoches = 64\n",
    "n_batches = 4096\n",
    "\n",
    "losses = np.zeros((n_epoches, n_batches), dtype='float32')\n",
    "\n",
    "opt_clf = torch.optim.Adam(clf.parameters(), lr=1e-3)\n",
    "\n",
    "for i in range(n_epoches):\n",
    "    for j in range(n_batches):\n",
    "        ### define training procedure here\n",
    "        indx = torch.randint(0, data_train.shape[0], size=(32, ))\n",
    "        X_batch, y_batch, z_batch = X_train[indx], y_train[indx], z_train[indx]\n",
    "        \n",
    "        losses[i, j] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_losses(classifier=losses_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adversary(torch.nn.Module):\n",
    "    ### define adversary here\n",
    "    ### don't forget about torch.squeeze\n",
    "    def __init__(self, ):\n",
    "        super(Adversary, self).__init__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pclf = Classifier().to(device)\n",
    "\n",
    "### define pivoted classifier loss here\n",
    "loss_fn_pclf = None\n",
    "\n",
    "adv = Adversary().to(device)\n",
    "\n",
    "### define adversary loss here\n",
    "loss_fn_adv = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epoches = 64\n",
    "n_batches = 1024\n",
    "\n",
    "losses_clf = np.zeros((n_epoches, n_batches), dtype='float32')\n",
    "losses_adv = np.zeros((n_epoches, n_batches), dtype='float32')\n",
    "\n",
    "opt_pclf = torch.optim.Adam(pclf.parameters(), lr=1e-3)\n",
    "opt_adv = torch.optim.Adamax(adv.parameters(), lr=5e-3)\n",
    "\n",
    "for i in range(n_epoches):\n",
    "    for j in range(n_batches):\n",
    "        for k in range(16):\n",
    "            indx = torch.randint(0, data_train.shape[0], size=(32, ))\n",
    "            X_batch, y_batch, z_batch = X_train[indx], y_train[indx], z_train[indx]\n",
    "            \n",
    "            ### define adversary training here\n",
    "    \n",
    "        indx = torch.randint(0, data_train.shape[0], size=(32, ))\n",
    "        X_batch, y_batch, z_batch = X_train[indx], y_train[indx], z_train[indx]\n",
    "        \n",
    "        ### define pivoted classifier training here\n",
    "        \n",
    "        losses_clf[i, j] = 0.0\n",
    "        losses_adv[i, j] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_losses(classifier=losses_clf, adversary=losses_adv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuisance_metric_plot([\n",
    "        get_test_predictions(clf),\n",
    "        get_test_predictions(pclf),\n",
    "    ],\n",
    "    labels=labels_test,\n",
    "    nuisance=nuisance_test,\n",
    "    metric_fn=roc_auc_score,\n",
    "    names=['non-pivoted', 'pivoted']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "pivot.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
